{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "genetic-thursday",
   "metadata": {},
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "velvet-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-fishing",
   "metadata": {},
   "source": [
    "#### Reading the datasets (Train, Test and Meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medieval-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:/Users/gmadh/Desktop/GaTech/SUMMER 2021/ISYE 6740 Machine Learning/Project'\n",
    "\n",
    "## Reading the meta dataset\n",
    "meta_data = pd.read_csv(\"Data/Meta.csv\")\n",
    "## Getting the number of classes from the Meta dataset\n",
    "classes = meta_data.shape[0]\n",
    "\n",
    "## Loading the sample image for each class from Meta dataset\n",
    "meta_img = []\n",
    "meta_class = []\n",
    "meta_path = f'{base_path}/Data/Meta/'\n",
    "meta_files = os.listdir(meta_path)\n",
    "for file in meta_files:\n",
    "    '''\n",
    "    Note: I am not resizing these images as I will use them for EDA purposes only.\n",
    "    '''\n",
    "    image = cv2.imread(meta_path+file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    meta_img.append(image)\n",
    "    meta_class.append(file.split('.')[0])\n",
    "    \n",
    "## Reading the Train data set (consists of images in multiple folders).This piece of code will iteratively read images from every folder.\n",
    "'''\n",
    "Two lists are populated. The raw training images are of different resolutions. They are loaded as such in train_data_raw. \n",
    "For purpose of modeling, all images are resized to a common resolution (30x30) and loaded into train_data\n",
    "'''\n",
    "\n",
    "train_data_raw = []\n",
    "train_data=[]\n",
    "train_labels=[]\n",
    "\n",
    "res = 30\n",
    "\n",
    "for c in range(classes) :\n",
    "    path = f'{base_path}/Data/Train/{c}/'.format(c)\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        train_image = cv2.imread(path+file)\n",
    "        train_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2RGB)\n",
    "        image_resized = cv2.resize(train_image, (res, res), interpolation = cv2.INTER_AREA)\n",
    "        train_data.append(np.array(image_resized))\n",
    "        train_data_raw.append(train_image)\n",
    "        train_labels.append(c)\n",
    "        \n",
    "## Reading the Test data images \n",
    "test_csv = pd.read_csv(f'{base_path}/Data/Test.csv')\n",
    "test_img_path = test_csv['Path']\n",
    "\n",
    "## List containing class labels for test data\n",
    "test_labels = test_csv['ClassId'].values\n",
    "test_data = []  ## List to hold resized test images\n",
    "test_data_raw = []  ## List to hold test images in raw format\n",
    "\n",
    "for f in test_img_path:\n",
    "    test_image = cv2.imread(f'{base_path}/Data/' + f)\n",
    "    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "    image_resized = cv2.resize(test_image, (res, res), interpolation = cv2.INTER_AREA)\n",
    "    test_data.append(np.array(image_resized))\n",
    "    test_data_raw.append(test_image)\n",
    "    \n",
    "    #from PIL import Image\n",
    "    #image_from_array = Image.fromarray(image, 'RGB')\n",
    "    #resized_image = np.array(image_from_array.resize((30, 30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-strand",
   "metadata": {},
   "source": [
    "#### Grouping the classes into 6 categories from 43 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "purple-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating groups of classes and getting indexes of group elements from test and train datatsets.\n",
    "groups = {'speed':[0,1,2,3,4,5,7,8], 'prohibitory':[9,10,15,16], 'derestriction':[6,32,41,42], 'mandatory':[33,34,35,36,37,38,39,40], 'danger':[11,18,19,20,21,22,23,24,25,26,27,28,29,30,31], 'other':[12,14,13,17]}\n",
    "group_labels = {'speed':1, 'prohibitory':2, 'derestriction':3, 'mandatory':4, 'danger':5, 'other':6}\n",
    "\n",
    "group_indices_train = {}\n",
    "group_indices_test = {}\n",
    "\n",
    "for k in groups.keys():\n",
    "    group_indices_train[k] = np.where(np.isin(np.array(train_labels), groups[k]) == True)[0]\n",
    "    group_indices_test[k] = np.where(np.isin(np.array(test_labels), groups[k]) == True)[0]\n",
    "    \n",
    "## Creating new labels for train and test datasets\n",
    "train_lbl_grp = np.array(train_labels)\n",
    "test_lbl_grp = np.array(test_labels)\n",
    "\n",
    "## Updating new label values for each group\n",
    "for k,v in group_labels.items():  ##New group labels\n",
    "    train_lbl_grp[group_indices_train[k]] = v\n",
    "    test_lbl_grp[group_indices_test[k]] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-mercury",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-penny",
   "metadata": {},
   "source": [
    "#### Applying below pre-processing techniques\n",
    "\n",
    "1. Resizing the data to 30 * 30 * 3 dimensions to have a common resolution for modeling (Already done and loaded in train_data and test_data)\n",
    "2. Scaling the data by diving by 255. \n",
    "3. Resampling the data to level the class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-puppy",
   "metadata": {},
   "source": [
    "### Modeling using all 2700 pixels (common resolution) including RGB (6 classes) - Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "floating-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the train data\n",
    "train_arr = np.array(train_data)\n",
    "train_arr = train_arr.reshape((train_arr.shape[0], 30*30*3))\n",
    "train_data_scaled = train_arr.astype(float)/255\n",
    "\n",
    "## Scaling the test data\n",
    "test_arr = np.array(test_data)\n",
    "test_arr = test_arr.reshape((test_arr.shape[0], 30*30*3))\n",
    "test_data_scaled = test_arr.astype(float)/255\n",
    "\n",
    "## Labels : train_lbl_grp, test_lbl_grp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-inspector",
   "metadata": {},
   "source": [
    "#### Down Sampling the data to balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "moral-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_Sampled, y_Sampled = rus.fit_resample(train_data_scaled, train_lbl_grp)\n",
    "\n",
    "## Splitting the data into test/train for modeling  (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Sampled,y_Sampled, test_size=0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "monthly-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.717\n",
      "Config: {'n_components': 5, 'solver': 'svd'}\n"
     ]
    }
   ],
   "source": [
    "## Cross Validation to Tune / Identify best hyperparameters for LDA model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "grid['n_components'] = np.arange(5,20,1)\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "#scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surgical-exhibition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting model after cross-validation\n",
    "\n",
    "model = LinearDiscriminantAnalysis(n_components=5,solver = 'svd')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-croatia",
   "metadata": {},
   "source": [
    "#### Validation Data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "changing-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaidation accuracy for LDA model is :  0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict(X_test)\n",
    "print(\"Vaidation accuracy for LDA model is : \", accuracy_score(y_test,val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-billy",
   "metadata": {},
   "source": [
    "#### Test Data Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hidden-conference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for LDA model is :  0.7650039588281868\n",
      "[[3388  308  184  109   91   90]\n",
      " [ 122 1219   47   41   32   39]\n",
      " [  15   15  321    8    0    1]\n",
      " [ 127  119   84 1296   64   80]\n",
      " [ 217  180  145   97 2048  103]\n",
      " [ 140  162  140  120   88 1390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.81      0.83      4170\n",
      "           2       0.61      0.81      0.70      1500\n",
      "           3       0.35      0.89      0.50       360\n",
      "           4       0.78      0.73      0.75      1770\n",
      "           5       0.88      0.73      0.80      2790\n",
      "           6       0.82      0.68      0.74      2040\n",
      "\n",
      "    accuracy                           0.77     12630\n",
      "   macro avg       0.71      0.78      0.72     12630\n",
      "weighted avg       0.80      0.77      0.77     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_data_scaled)\n",
    "\n",
    "print(\"Test accuracy for LDA model is : \", accuracy_score(test_lbl_grp,pred))\n",
    "print(confusion_matrix(test_lbl_grp, pred))\n",
    "print(classification_report(test_lbl_grp, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-stick",
   "metadata": {},
   "source": [
    "### Modeling using all 2700 pixels (common resolution) including RGB (6 classes) - No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "magnetic-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the train data\n",
    "train_arr = np.array(train_data)\n",
    "train_arr = train_arr.reshape((train_arr.shape[0], 30*30*3))\n",
    "train_data_scaled = train_arr.astype(float)/255\n",
    "\n",
    "## Scaling the test data\n",
    "test_arr = np.array(test_data)\n",
    "test_arr = test_arr.reshape((test_arr.shape[0], 30*30*3))\n",
    "test_data_scaled = test_arr.astype(float)/255\n",
    "\n",
    "## Labels : train_lbl_grp, test_lbl_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "attended-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the data into test/train for modeling  (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_scaled,train_lbl_grp, test_size=0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "southern-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.895\n",
      "Config: {'n_components': 5, 'solver': 'svd'}\n"
     ]
    }
   ],
   "source": [
    "## Cross Validation to Tune / Identify best hyperparameters for LDA model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "grid['n_components'] = np.arange(5,20,1)\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "#scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "silver-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting model after cross-validation\n",
    "model = LinearDiscriminantAnalysis(n_components=5,solver = 'svd')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "inner-helena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaidation accuracy for LDA model is :  0.8908441724049987\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict(X_test)\n",
    "print(\"Vaidation accuracy for LDA model is : \", accuracy_score(y_test,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "hourly-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for LDA model is :  0.866825019794141\n",
      "[[4083   50   15    5   11    6]\n",
      " [ 317 1164    0   12    7    0]\n",
      " [ 125   11  223    1    0    0]\n",
      " [ 284   10    6 1457    7    6]\n",
      " [ 335   32   16    5 2363   39]\n",
      " [ 268   34   30   31   19 1658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.98      0.85      4170\n",
      "           2       0.89      0.78      0.83      1500\n",
      "           3       0.77      0.62      0.69       360\n",
      "           4       0.96      0.82      0.89      1770\n",
      "           5       0.98      0.85      0.91      2790\n",
      "           6       0.97      0.81      0.88      2040\n",
      "\n",
      "    accuracy                           0.87     12630\n",
      "   macro avg       0.89      0.81      0.84     12630\n",
      "weighted avg       0.89      0.87      0.87     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_data_scaled)\n",
    "\n",
    "print(\"Test accuracy for LDA model is : \", accuracy_score(test_lbl_grp,pred))\n",
    "print(confusion_matrix(test_lbl_grp, pred))\n",
    "print(classification_report(test_lbl_grp, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "provincial-granny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39209"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-flower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-jimmy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "classical-frost",
   "metadata": {},
   "source": [
    "### Model efficiency using Gray scale image resolution (6 classes) - Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "outstanding-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the train data\n",
    "train_arr = np.array(train_data)\n",
    "train_arr = np.mean(train_arr, -1)\n",
    "train_arr = train_arr.reshape((train_arr.shape[0], 30*30))\n",
    "train_data_scaled = train_arr.astype(float)/255\n",
    "\n",
    "## Scaling the test data\n",
    "test_arr = np.array(test_data)\n",
    "test_arr = np.mean(test_arr, -1)\n",
    "test_arr = test_arr.reshape((test_arr.shape[0], 30*30))\n",
    "test_data_scaled = test_arr.astype(float)/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-start",
   "metadata": {},
   "source": [
    "#### Down Sampling data and checking efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labels : train_lbl_grp, test_lbl_grp\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_Sampled, y_Sampled = rus.fit_resample(train_data_scaled, train_lbl_grp)\n",
    "\n",
    "## Splitting into test/validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Sampled,y_Sampled, test_size=0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "improving-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting an LDA on dataset after PCA with default parameters to understand fit\n",
    "model = LinearDiscriminantAnalysis()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acceptable-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.811 (0.017)\n"
     ]
    }
   ],
   "source": [
    "print('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "moved-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.797\n",
      "Config: {'n_components': 5, 'solver': 'svd'}\n"
     ]
    }
   ],
   "source": [
    "#### Cross validation to get best hyper parameters\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "grid['n_components'] = np.arange(5,20,1)\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X_train, y_train)\n",
    "# summarize\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "mathematical-forty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting model with best hyper-parameters from CV\n",
    "\n",
    "model = LinearDiscriminantAnalysis(n_components=5,solver = 'svd')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-monkey",
   "metadata": {},
   "source": [
    "#### Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "romance-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaidation accuracy for LDA model is :  0.8121345029239766\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict(X_test)\n",
    "print(\"Vaidation accuracy for LDA model is : \", accuracy_score(y_test,val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-sudan",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "short-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for LDA model is :  0.7673792557403009\n",
      "[[3479  224  133  271   10   53]\n",
      " [  29 1302   13  128    7   21]\n",
      " [  29   25  297    0    0    9]\n",
      " [  83  230   28 1177   33  219]\n",
      " [ 153  185   43  266 2062   81]\n",
      " [  49  155   44  392   25 1375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.83      0.87      4170\n",
      "           2       0.61      0.87      0.72      1500\n",
      "           3       0.53      0.82      0.65       360\n",
      "           4       0.53      0.66      0.59      1770\n",
      "           5       0.96      0.74      0.84      2790\n",
      "           6       0.78      0.67      0.72      2040\n",
      "\n",
      "    accuracy                           0.77     12630\n",
      "   macro avg       0.72      0.77      0.73     12630\n",
      "weighted avg       0.80      0.77      0.78     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_data_scaled)\n",
    "\n",
    "print(\"Test accuracy for LDA model is : \", accuracy_score(test_lbl_grp,pred))\n",
    "print(confusion_matrix(test_lbl_grp, pred))\n",
    "print(classification_report(test_lbl_grp, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-three",
   "metadata": {},
   "source": [
    "### Model efficiency using Gray scale image resolution (6 classes) - No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sexual-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the train data\n",
    "train_arr = np.array(train_data)\n",
    "train_arr = np.mean(train_arr, -1)\n",
    "train_arr = train_arr.reshape((train_arr.shape[0], 30*30))\n",
    "train_data_scaled = train_arr.astype(float)/255\n",
    "\n",
    "## Scaling the test data\n",
    "test_arr = np.array(test_data)\n",
    "test_arr = np.mean(test_arr, -1)\n",
    "test_arr = test_arr.reshape((test_arr.shape[0], 30*30))\n",
    "test_data_scaled = test_arr.astype(float)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "greenhouse-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into test/validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_scaled,train_lbl_grp, test_size=0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fiscal-storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.829\n",
      "Config: {'n_components': 5, 'solver': 'svd'}\n"
     ]
    }
   ],
   "source": [
    "#### Cross validation to get best hyper parameters\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "grid['n_components'] = np.arange(5,20,1)\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X_train, y_train)\n",
    "# summarize\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "rubber-asthma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fitting model with best hyper-parameters from CV\n",
    "\n",
    "model = LinearDiscriminantAnalysis(n_components=5,solver = 'svd')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "favorite-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaidation accuracy for LDA model is :  0.8291252231573578\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict(X_test)\n",
    "print(\"Vaidation accuracy for LDA model is : \", accuracy_score(y_test,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "protected-perfume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for LDA model is :  0.7996041171813143\n",
      "[[3964   39   44  101    8   14]\n",
      " [ 288 1089    0   93   10   20]\n",
      " [ 139   18  189    0    0   14]\n",
      " [ 314   65   13 1218   33  127]\n",
      " [ 388   37   13   89 2186   77]\n",
      " [ 196   54   20  292   25 1453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.95      0.84      4170\n",
      "           2       0.84      0.73      0.78      1500\n",
      "           3       0.68      0.53      0.59       360\n",
      "           4       0.68      0.69      0.68      1770\n",
      "           5       0.97      0.78      0.87      2790\n",
      "           6       0.85      0.71      0.78      2040\n",
      "\n",
      "    accuracy                           0.80     12630\n",
      "   macro avg       0.79      0.73      0.76     12630\n",
      "weighted avg       0.81      0.80      0.80     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_data_scaled)\n",
    "\n",
    "print(\"Test accuracy for LDA model is : \", accuracy_score(test_lbl_grp,pred))\n",
    "print(confusion_matrix(test_lbl_grp, pred))\n",
    "print(classification_report(test_lbl_grp, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-speech",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
