---
output:
  word_document: default
  html_document: default
  pdf_document: default
---
#Using the 20 years of daily high temperature data for Atlanta (July through October) from Question 6.2 (file temps.txt), build and use an exponential smoothing model to help make a judgment of whether the unofficial end of summer has gotten later over the 20 years.  (Part of the point of this assignment is for you to think about how you might use exponential smoothing to answer this question. Feel free to combine it with other models if you’d like to. There’s certainly more than one reasonable approach.) 

#Note: in R, you can use either HoltWinters (simpler to use) or the smooth package’s es function (harder to use, but more general).  If you use es, the Holt-Winters model uses model=”AAM” in the function call (the first and second constants are used “A”dditively, and the third (seasonality) is used “M”ultiplicatively; the documentation doesn’t make that clear). 


#Approach:
For this question, I am following the below approach

1) Get the temps data into a Dataframe and convert it to a time series object to build a model

2) Build Exponential smoothing model using HoltWinters function in R (using default parameters and manual parameters for understanding). Observe the results

3) Experiment es function of R for exponential smoothing

4) Copy the fitted values from the HoltWinters model (both estimated xhat values of temperature and seasonality information)to a CSV file

5) Using CUSUM approach, identify the un-official summer end dates for the data generated by exponential smoothing
and compare the same with the dates from the previous CUSUM approach with original data.

6) Use CUSUM approach with seasonality values and observe the summer end dates.


#Extracting the data and generating a time series object using R

```{r}
library(smooth)
library(greybox)
library(Mcomp)

#Reading data
temps <- read.table("temps.txt", header = TRUE, sep='\t')


#Analyzing the data
nrow(temps)
str(temps)

```

#The data has 123 rows with temperature values from July - October for the years from 1996 - 2015

```{r}

#Converting the dataframe to a vector object that will be later converted to a time series object

temp <- unlist(temps[,2:21])

#Converting the data into a time-series object
#Here we are considering each year as a unit of time. Since there are 123 observations for every year, we repeat the timeseries data after a frequency of 123
temp_ts <- ts(unlist(temps[,2:21]), start=c(1996,1), frequency = 123)

#Plotting the time series object

plot.ts(temp_ts)


```
#From the plot, we can observe that there is a cyclic pattern (seasonality) in the data. Temperatures have a high value at one point of time and then drop to a low value at another point of time cyclically. The random variances with the pattern also tend to seem constant over the period of time.

# To observe the components of the time series object (trend, seasonality) more clearly, let's decompose the model

```{r}

#Decompose the time series data to observe the variation in trend, seasonality
temp_comp <- decompose(temp_ts)

str(temp_comp)

plot(temp_comp)

```

# The time series contains 3 components : Seasonal, trend and a random noise component. Seasonal component shows if there are any cyclic or seasonal patterns in the data over time. Trend indicates if there is any upward or downward trend in data over time. Random noise simply explains randomness in the data.

# From the plot, we can see that the seasonality is very obvious and there are clear cyclic patterns that are not random. The trend, on the other hand does not increase or decrease over the period of time. There is an upward trend from 2010 to 2012, but it doesn't seem to repeat to make a concete conclusion on the trend factor. The random noise also seems to be constant over time. The plot also suggests that the type of model best suited would be an additive model.

# With this initial analysis of the tme series object, we can build can exponential smoothing model to see how it performs. 

# Fitting a time series model using HoltWinters() function in R

```{r}
#1) Building an additive model setting default values for alpha, beta and gamma

time_all <- HoltWinters(temp_ts,seasonal = c("additive"))

str(time_all)

time_all$alpha
time_all$beta
time_all$gamma

time_all$SSE

head(time_all$fitted)

```

# The model is built with NULL values of Alpha, beta and Gamma. This means that the HoltWInters itself would chose an optimum value for these parameters. In additon, the model also outputs the Sum of squares of errors(SSE) and the coefficients used for the model.

# From the above results, we observe that Beta parameter = 0, which means that trend component of the original data is retained and there is not much change.

# Alpha = 0.66, which is closer to 1, which means the estimate of level of the current time point is based more on the recent observations than past observations.

#Gamma = 0.624, which is closer to 1 which indicates that estimate of seasonal component at the current time point is based more on recent observations than past observations.

#Looking at the plot of the data:
```{r}

plot(time_all)
```

# The red line in the plot is the observed pattern as a result of exponential smoothing. The black line represents the original data. We observe that there is no red pattern for an intial period(1996). This is because the model uses this portion of the data (first year) as the baseline to build the model further.
#Also, the fitted values are bad initialy, but gets smoother and closer to the black line as time increases.

# Also, we observe that the fitted values of the model include xhat - which is the estimated temperature at current point of time. 
# level - this represents the mean temperature at every level of building the model.
#seasonality-  deviation from mean value due to a seasonal pattern
#trend - estmate of trend or a change between two points of time.

#Observing the seasonality in temperatures
```{r}
plot(temp_ts,time_all$fitted[,4])
```


# We observe that the lower temperatues like 60 are shown with a negative seasonality and the higher temperatures are represented with a positive seasonality.

#EXPERIMENTING with manual values for alpha, beta, gamma

```{r}

time_manual <- HoltWinters(temp_ts,alpha = 0.2, gamma = 0.2)


time_manual$alpha
time_manual$beta
time_manual$gamma

head(time_manual$fitted)

time_manual$SSE   #75066.92

```
## Thie model has a higher SSE than the previous model. That is because Holtwinters() chose the most optimal value for alpha, beta and gamma

# Comparing the two model plots

```{r}

par(mfrow=c(2,1))
plot(time_all, main = "Holt-Winters Filtering Default")
plot(time_manual, main = "Holt-Winters Filtering Manual")

```


# We can observe that Default fits the model well whereas  Manual has more smoothing in the lower peaks.

## EXPERIMENTING es FUNCTION FOR EXPONENTIAL SMOOTHING

```{r}
mult_model <- es(temp_ts, model = 'AAM')

mult_SSE <- (temp_ts[124:1260] - mult_model$fitted[124:1260])^2 %>% sum

mult_model

head(mult_model$fitted)

mult_SSE

```
## Interestingly this model choses a very low value for seasonality.
# The SSE however is lower for this model - 22373.2

# Since an additive model is better for the seasonal data we have, we can proceed with the results from the first model built.

# To check if the un-official summer has gotten longer with exponential smoothing , we can reuse the CUSUM model built in the previous assignment. Exporting the results (xhat and season) values to a CSV file

```{r}

## Using the results of exponential smoothing to identify if un-official summer has gotten later over the years
#Exporting the data to csv to perform CUSUM in excel
xhat <- matrix(time_all$fitted[,1],nrow=123)
season <- matrix(time_all$fitted[,4],nrow=123)

write.csv(xhat, file = "xhat.csv")
write.csv(season, file = "season.csv")

```

## ANALYSIS OF XHAT (ESTIMATED TEMPERATURE VALUES) IN CUSUM AND COMPARING AGAINST ORIGINAL DATA'S UN-OFFICIAL SUMMER END DATES
## Please refer the excel files for detailed analysis on the data.

Below are details of how CUSUM was performed last time. This time, I am replacing the actual temperatures with the temperatures obtained from the exponential smoothing results(xhat). Data for the year 1996 alone used the original data, since smoothing model does not estimate the first year.

a) Firstly, to get the mean value (mu) for CUSUM approach, I am considering average of July month's data every year as the mean for that year. I am using this month since visually, the temperature seems to be hot for almost all days in July. So this will be a good set of data to average and set a standard mean.
b) With this mean value, we have to use CUSUM approach to observe a decrease in the temperatures over the days every year to identify the unofficial end of summer every year.
c) For a start, I take C = 0.5 * Standard Deviation (of the temperatures in the month of July).
T = 5* Standard Deviation (of the temperatures in the month of July).
d) With these values, I use the CUSUM approach formula to compute detecting a decrease.

st = max{0, st-1 + (mu - xt - C)}
Change Detected , if St >= T

# Please refer to the attached excel sheet (Exponential_Smoothing_Analysis.xlsx) for calculations and results.
# temps_smooth  - This sheet contains the temperature estimates from the exponential smoothing model
# Summer_end - This sheet contains the calculations in excel to compute the CUSUM change detector. 

# The Summer_end_results sheet shows  the comparison of the un-official end dates with the original data and data after smoothing.

#From the results, I am not observing a change in the un-official summer end dates from the original data set. The estimated values seem close to the orginal and we could imply that exponential smoothing model fit the data as closely as possible.



## ANALYSIS OF SEASONALITY (Deviation from the mean value due to seasonal effect) IN CUSUM AND COMPARING AGAINST ORIGINAL DATA'S UN-OFFICIAL SUMMER END DATES

#For this analysis, the seasonality values are at a different scale than the temperatures. However, since all our data are now at the seasonal values scale, we could apply CUSUM with the mean and SD of this value to analyse the un-official summer end date. 1996 is not considered in this analysis

#Refer the excel Exponential_Smoothing_Analysis_Seasonality.xlsx for details.
# temps_smooth  - This sheet contains the seasonality estimates from the exponential smoothing model
# Summer_end - This sheet contains the calculations in excel to compute the CUSUM change detector. 


# The Summer_end_results sheet shows  the comparison of the un-official end dates with the original data and data after smoothing.


## Interestingly, when we apply CUSUM on the seasonality data, we observe that initially, the un-official summer end dates are earlier than the original model, However, the end dates tend to be sligher later after 2004. Also, looking at the un-official summer end dates from 1997 - 2015 , the end date seems to be constant for all the years (somewhere around 20th of September every year). The exponential smoothing model accounts for the seasonality well, and has fitted seasonality without any randomness. 